# -*- coding:UTF-8 -*-
#coding=utf-8
# 唐诗
import requests
import datetime
from bs4 import BeautifulSoup
from urllib.parse import unquote
import urllib
#target = 'https://www.gushiwen.org/gushi/tangshi.aspx'
target = 'https://so.gushiwen.org/gushi/songsan.aspx'
req = requests.get(url=target)
html_doc=str(req.content,req.encoding) #html_doc=html.decode("utf-8","ignore")

bf = BeautifulSoup(html_doc)
texts = bf.find_all('a' ) 
#texts = bf.find_all('td', class_ = 'p9' ) 
print(len(texts))
#print(texts)
for tt in texts:
    uu = tt.get('href')
    #print(uu,tt.get_text())
    if ('shiwenv' in uu):
        uu = tt.get('href')
        print(tt.string,uu)
        file1 = open("/Users/rong/work/ci/" + tt.get_text() + ".md","a") 
        #shi = requests.get( uu)
        shi = requests.get(url='https://so.gushiwen.org/'+uu)
        shi_doc=str(shi.content,shi.encoding) #html_doc=html.decode("utf-8","ignore")
        shi_bf = BeautifulSoup(shi_doc)
        main3 = shi_bf.find_all('div', class_ = 'main3' ) 
        print( main3[0].textarea.get_text())
        file1.write(main3[0].textarea.get_text() + "\n")
        #main3.find_all('div')
        #main3.find(class_='sons') hasattr(t, "name")
        for p in main3:
            #sons = p.find_all('div',class_='contson')
            #for ccc in sons:   
            #    print (ccc.get_text())
            fanyi677  = p.find_all('div',class_='contyishang')
            for ccc in fanyi677:   
                print("======")
                print (ccc.get_text())
                file1.write(ccc.get_text() + "\n")
        

